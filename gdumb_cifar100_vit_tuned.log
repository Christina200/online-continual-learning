/home/xw6956/anaconda3/envs/lora_vit/lib/python3.10/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice
  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,
/home/xw6956/anaconda3/envs/lora_vit/lib/python3.10/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
Namespace(num_runs=1, seed=0, val_size=0.1, num_val=3, num_runs_val=3, error_analysis=False, verbose=True, store=False, save_path=None, agent='GDUMB', update='random', retrieve='random', optimizer='Adam', learning_rate=0.0001, epoch=1, batch=4, test_batch=128, weight_decay=0.0001, num_tasks=10, fix_order=True, plot_sample=False, data='cifar100', cl_type='nc', ns_factor=(0.0, 0.4, 0.8, 1.2, 1.6, 2.0, 2.4, 2.8, 3.2, 3.6), ns_type='noise', ns_task=(1, 1, 2, 2, 2, 2), online=True, mem_size=1000, eps_mem_batch=10, lambda_=100, alpha=0.9, fisher_update_after=50, subsample=50, gss_mem_strength=10, gss_batch_size=10, k=5, aser_type='asvm', n_smp_cls=2.0, stm_capacity=1000, classifier_chill=0.01, log_alpha=-300, minlr=0.0005, clip=10.0, mem_epoch=30, labels_trick=False, separated_softmax=False, kd_trick=False, kd_trick_star=False, review_trick=False, ncm_trick=False, mem_iters=1, min_delta=0.0, patience=0, cumulative_delta=False, temp=0.07, buffer_tracker=False, warmup=4, head='mlp', cuda=True)
Setting up data stream
Files already downloaded and verified
Files already downloaded and verified
data setup time: 0.8683459758758545
Task: 0, Labels:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Task: 1, Labels:[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
Task: 2, Labels:[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]
Task: 3, Labels:[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]
Task: 4, Labels:[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]
Task: 5, Labels:[50, 51, 52, 53, 54, 55, 56, 57, 58, 59]
Task: 6, Labels:[60, 61, 62, 63, 64, 65, 66, 67, 68, 69]
Task: 7, Labels:[70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
Task: 8, Labels:[80, 81, 82, 83, 84, 85, 86, 87, 88, 89]
Task: 9, Labels:[90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
-----------run 0 training batch 0-------------
size: (5000, 32, 32, 3), (5000,)
[0.562 0.    0.    0.    0.    0.    0.    0.    0.    0.   ]
-----------run 0 training batch 1-------------
size: (5000, 32, 32, 3), (5000,)
[0.336 0.293 0.    0.    0.    0.    0.    0.    0.    0.   ]
-----------run 0 training batch 2-------------
size: (5000, 32, 32, 3), (5000,)
[0.257 0.249 0.241 0.    0.    0.    0.    0.    0.    0.   ]
-----------run 0 training batch 3-------------
size: (5000, 32, 32, 3), (5000,)
[0.205 0.204 0.201 0.2   0.    0.    0.    0.    0.    0.   ]
-----------run 0 training batch 4-------------
size: (5000, 32, 32, 3), (5000,)
[0.158 0.133 0.137 0.146 0.188 0.    0.    0.    0.    0.   ]
-----------run 0 training batch 5-------------
size: (5000, 32, 32, 3), (5000,)
[0.13  0.085 0.169 0.15  0.144 0.174 0.    0.    0.    0.   ]
-----------run 0 training batch 6-------------
size: (5000, 32, 32, 3), (5000,)
[0.149 0.109 0.14  0.107 0.149 0.215 0.172 0.    0.    0.   ]
-----------run 0 training batch 7-------------
size: (5000, 32, 32, 3), (5000,)
[0.091 0.078 0.089 0.085 0.096 0.114 0.184 0.099 0.    0.   ]
-----------run 0 training batch 8-------------
size: (5000, 32, 32, 3), (5000,)
[0.112 0.057 0.104 0.059 0.09  0.088 0.117 0.134 0.066 0.   ]
-----------run 0 training batch 9-------------
size: (5000, 32, 32, 3), (5000,)
[0.071 0.077 0.119 0.042 0.054 0.119 0.109 0.084 0.09  0.087]
-----------run 0-----------avg_end_acc 0.0852-----------train time 2064.7879791259766
----------- Total 1 run: 2065.6563622951508s -----------
----------- Avg_End_Acc (0.0852, nan) Avg_End_Fgt (0.1342, nan) Avg_Acc (0.2052703174603175, nan) Avg_Bwtp (0.0, nan) Avg_Fwt (0.0, nan)-----------
