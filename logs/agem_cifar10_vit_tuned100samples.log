/home/christina/anaconda3/envs/lora_vit/lib/python3.11/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice
  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,
/home/christina/anaconda3/envs/lora_vit/lib/python3.11/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
Namespace(num_runs=1, seed=0, val_size=0.1, num_val=3, num_runs_val=3, error_analysis=False, verbose=True, store=False, save_path=None, agent='AGEM', update='random', retrieve='random', optimizer='Adam', learning_rate=0.0001, epoch=1, batch=4, test_batch=128, weight_decay=0.0001, num_tasks=5, fix_order=True, plot_sample=False, data='cifar10', cl_type='nc', ns_factor=(0.0, 0.4, 0.8, 1.2, 1.6, 2.0, 2.4, 2.8, 3.2, 3.6), ns_type='noise', ns_task=(1, 1, 2, 2, 2, 2), online=True, mem_size=1000, eps_mem_batch=10, lambda_=100, alpha=0.9, fisher_update_after=50, subsample=50, gss_mem_strength=10, gss_batch_size=10, k=5, aser_type='asvm', n_smp_cls=2.0, stm_capacity=1000, classifier_chill=0.01, log_alpha=-300, minlr=0.0005, clip=10.0, mem_epoch=70, labels_trick=False, separated_softmax=False, kd_trick=False, kd_trick_star=False, review_trick=False, ncm_trick=False, mem_iters=1, min_delta=0.0, patience=0, cumulative_delta=False, temp=0.07, buffer_tracker=False, warmup=4, head='mlp', cuda=True)
Setting up data stream
Files already downloaded and verified
Files already downloaded and verified
data setup time: 1.1147780418395996
Task: 0, Labels:[0, 1]
Task: 1, Labels:[2, 3]
Task: 2, Labels:[4, 5]
Task: 3, Labels:[6, 7]
Task: 4, Labels:[8, 9]
buffer has 1000 slots
-----------run 0 training batch 0-------------
size: (200, 32, 32, 3), (200,)
==>>> it: 1, avg. loss: 1.899384, running train acc: 0.375
[0.745 0.    0.    0.    0.   ]
-----------run 0 training batch 1-------------
size: (200, 32, 32, 3), (200,)
==>>> it: 1, avg. loss: 7.846849, running train acc: 0.000
[0.     0.5115 0.     0.     0.    ]
-----------run 0 training batch 2-------------
size: (200, 32, 32, 3), (200,)
==>>> it: 1, avg. loss: 6.570991, running train acc: 0.000
[0.     0.     0.5695 0.     0.    ]
-----------run 0 training batch 3-------------
size: (200, 32, 32, 3), (200,)
==>>> it: 1, avg. loss: 6.949637, running train acc: 0.000
[0.    0.    0.    0.657 0.   ]
-----------run 0 training batch 4-------------
size: (200, 32, 32, 3), (200,)
==>>> it: 1, avg. loss: 6.742035, running train acc: 0.000
[0.    0.    0.    0.    0.528]
-----------run 0-----------avg_end_acc 0.1056-----------train time 181.04683804512024
----------- Total 1 run: 182.16167950630188s -----------
----------- Avg_End_Acc (0.1056, nan) Avg_End_Fgt (0.49660000000000004, nan) Avg_Acc (0.29208666666666666, nan) Avg_Bwtp (0.0, nan) Avg_Fwt (0.0, nan)-----------
